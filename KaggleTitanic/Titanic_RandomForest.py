# -*- coding: utf-8 -*-
"""KaggleTitanic

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jGrC90Xaw1cKW5HKXsdhMIznlttgsMXe
"""

from IPython import get_ipython
from IPython.display import display
import pandas as pd
import numpy as np

data = pd.read_csv('train.csv')

def clean_data(df):
  #Fill in holes
  df['Age'].fillna(df['Age'].median(), inplace=True)
  #Replace empty age w/ median
  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
  #Replace embarked w mode(since its not numerical data)
  df['Fare'].fillna(df['Fare'].median(), inplace=True)
  #Replace empty fare w/ median

  #75% of cabin values are missing, dropping entire column


  #Remove irrelevant parameters(Name, Ticket, Cabin).
  #Include 'PassengerId' in the selected columns
  selected_columns = ['PassengerId', 'Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']
  if 'Survived' in df.columns:
     selected_columns.insert(1, 'Survived')  #Add it after PassengerId

  df_selected = df[selected_columns]
  #Converting Sex into bool
  df_cleaned = pd.get_dummies(df_selected, columns=['Sex'], drop_first=True)

  # Convert embarked into numerical data according to embarked_mapping
  embarked_mapping = {'S': 1, 'C': 2, 'Q': 3}
  df_cleaned['Embarked'] = df_cleaned['Embarked'].map(embarked_mapping)


  return df_cleaned

"""clean_data function should preprocess all the data relatively accurately. Cabin values are entirely gone, which could lead to decreased accuracy. This is what I did.
1. Remove irrelevant data
2. Convert categorical data into numbers
3. Fill in holes in data
"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import pandas as pd
import numpy as np


#Pass the cleaned data thru prev. function in the model training func
def treeModel(cleaned_df):
  #The output we want is if the people survived
  target_column = 'Survived'

  #Features(parameters) should be everything except survived column
  #Removed the line to drop 'PassengerId'
  features = cleaned_df.drop([target_column], axis=1)

  #Target column is survived
  target = cleaned_df[target_column]

  #n_estimators is amount of trees, random_state represents randomness
  model = RandomForestClassifier(
    n_estimators=100,
    max_depth=5,
    min_samples_split=10,
    min_samples_leaf=5,
    max_features='sqrt',
    random_state=42
)
  #Train the model with features and target variables
  model.fit(features, target)

  return model

"""This cell trains the random tree model, using "survived" as the target, and other passenger attributes as the features."""

#FIT THE MODEL IN THIS CELL

#Clean(preprocess) the training data w/ clean_data function.
cleaned_train_data = clean_data(data)

#Train the model w/ treeModel func - use the already cleaned datagrame
trained_model = treeModel(cleaned_train_data)

#Load the csv file we want to predict with
new_data = pd.read_csv('test.csv')

#Clean the new data using clean_data again
cleaned_new_data = clean_data(new_data)

# Prepare the new data for prediction
# Get the feature names and order from the training data
# The test data does not have a 'Survived' column, so we drop it from the training features before getting column names
training_features_columns = cleaned_train_data.drop('Survived', axis=1).columns

# Ensure the new data has the same columns and order as training data features
# Drop the 'Survived' column from the test data, as it's not a feature for prediction
# Also, ensure 'PassengerId' is present if your training included it
prediction_features = cleaned_new_data[training_features_columns]


# Make predictions on the new data using the trained model
predictions = trained_model.predict(prediction_features)



# To see the predictions:
print(predictions)

import pandas as pd
from google.colab import files

# Create a new DataFrame for the submission file
# Include 'PassengerId' from the cleaned test data and the predicted 'Survived' values
submission_df = pd.DataFrame({
    'PassengerId': cleaned_new_data['PassengerId'],
    'Survived': predictions
})

# Display the first few rows of the submission DataFrame to check
print(submission_df.head())

# Save the DataFrame to a new CSV file
# Set index=False to prevent pandas from writing the DataFrame index as a column in the CSV
submission_df.to_csv('test_with_predictions.csv', index=False)
files.download('test_with_predictions.csv')