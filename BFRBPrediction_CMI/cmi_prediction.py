# -*- coding: utf-8 -*-
"""CMI_Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B4rvitAIhJ29IReu9VhCZnsIUCQshXJO
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('train.csv')

#Preprocess the data by encoding all categorical features and normalizing numerical features.
#We can do this w/ standardscalar for numerical, and red hot encoding(T/F tables) for categorical
numerical_cols = df.select_dtypes(include=np.number).columns.tolist()
categorical_cols = df.select_dtypes(exclude=np.number).columns.tolist()

#Encode all the categorical columns. Drop 1 because if all other columns are 0, the last column is implied
#Red hot encoding
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

#Standard scalar makes all means 0 with standard deviation of 1. Apply this to all numerical columns
scaler = StandardScaler()
df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])

"""Preprocessing the entire train.csv file. Since some vals are numerical and categorical, we have to handle them differently. Explanations for everything are commented inside of the cells. Want to use a Time Series Transformer."""

from tensorflow.keras.preprocessing.sequence import pad_sequences

#Since model is time sensitive, group by sequence id to keep it chronological
df_grouped = df.groupby('sequence_id')

#Want to build a 3d dataframe to feed into the Transformer model.
#(num_sequences, sequence_length, num_features)

#Features are all of the things that can classify actions
features = [col for col in df.columns if col.startswith(('acc_', 'rot_', 'thm_', 'tof_'))]

#This holds all the sequences
X = []
#This holds all the features corresponding to the sequence
y = []


for seq_id, group in df_grouped:
    #Want it sorted by time so use sequence counter
    group_sorted = group.sort_values('sequence_counter')
    #Adding sequence_length and num_features into X array
    X.append(group_sorted[features].values)

    y.append(group_sorted['gesture'].iloc[0])

#Pad sequences so they all have the same length
X_padded = pad_sequences(X, padding='post', dtype='float32')  # shape = (num_sequences, max_seq_len, num_features)

#Label encode y if it's strings like 'pulling', 'adjusting'
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_encoded = le.fit_transform(y)

X_padded.shape
y_encoded.shape

"""Formats the data so that it can be used in a transformer model. Creating a 3d array w/ sequences, length of each sequence, and number of features"""

import tensorflow as tf
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split

#X_padded is the 3d tensor of inputs, y_encoded is labels,
#Other things r just random
X_train, X_val, y_train, y_val = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=42)

def build_transformer_model(input_shape, num_classes):
    inputs = layers.Input(shape=input_shape)

    # Initial projection
    x = layers.Dense(64)(inputs)
    x = layers.LayerNormalization()(x)

    # Multi-head self-attention
    attn_output = layers.MultiHeadAttention(num_heads=2, key_dim=32)(x, x)
    x = layers.Add()([x, attn_output])
    x = layers.LayerNormalization()(x)

    # Global pooling
    x = layers.GlobalAveragePooling1D()(x)

    # Dense layers
    x = layers.Dense(64, activation='relu')(x)
    x = layers.Dense(num_classes, activation='softmax')(x)

    # Model
    model = tf.keras.Model(inputs, x)
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

num_classes = len(np.unique(y_encoded))
input_shape = X_train.shape[1:]  # (sequence_length, num_features)

model = build_transformer_model(input_shape, num_classes)
#model.summary()

# --------------------------
# Step 7: Train the model
# --------------------------
model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=32
)

import pandas as pd
import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences

# ----------- Step 1: Load test file -----------
test_df = pd.read_csv('test.csv')

# Clean gesture column if present (safe to include)
if 'gesture' in test_df.columns:
    test_df['gesture'] = test_df['gesture'].str.strip().str.lower()

# ----------- Step 2: Extract sequences and features -----------
features = [col for col in test_df.columns if col.startswith(('acc_', 'rot_', 'thm_', 'tof_'))]

X_test = []
seq_ids = []

for seq_id, group in test_df.groupby('sequence_id'):
    group_sorted = group.sort_values('sequence_counter')
    X_test.append(group_sorted[features].values)
    seq_ids.append(seq_id)

# ----------- Step 3: Pad to match training sequence length -----------
X_test_padded = pad_sequences(
    X_test,
    padding='post',
    dtype='float32',
    maxlen=X_train.shape[1]  # use same sequence length as training
)

# ----------- Step 4: Predict using trained model -----------
y_pred_probs = model.predict(X_test_padded)
y_pred_classes = np.argmax(y_pred_probs, axis=1)

# ----------- Step 5: Decode class IDs to gesture labels -----------
y_pred_labels = le.inverse_transform(y_pred_classes)

# ----------- Step 6: Save predictions to CSV -----------
output_df = pd.DataFrame({
    'sequence_id': seq_ids,
    'predicted_gesture': y_pred_labels
})

output_df.to_csv('test_predictions.csv', index=False)